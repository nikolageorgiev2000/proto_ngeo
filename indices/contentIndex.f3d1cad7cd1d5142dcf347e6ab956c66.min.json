{"/":{"title":"Home","content":"\nHowdy. I'm Nikola. This is my personal website. It grows alongside my collection of interlinked notes.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Continuous-Function":{"title":"Continuous Function","content":"Given [[notes/Topological Space|topological spaces]] $\\mathcal{X}$ and $\\mathcal{Y}$, a function $f:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is *continuous* if the inverse image $f^{-1}(V)=U$ of an open set $V$ of $\\mathcal{Y}$ is an open set $U$ of $\\mathcal{X}$. Note how this generalizes the notion of a continuous function from real analysis - $f:\\mathbb{R}\\rightarrow \\mathbb{R}$ is continuous at $a$ if $f(a)=\\lim_{x\\rightarrow a}f(x)$. In other words, a function is continuous when points near $a$ give output near $f(a)$. [Table source](https://math.stackexchange.com/a/962688)\n$$\\begin{array}{|c|c|}\n\\hline\n\\text{Continuity on } \\Bbb R \u0026 \\text{Topological space} \\\\ \\hline\n\\text{Fix } \\varepsilon  \u0026 \\text{Fix a neighborhood }  V \\text{of } f(x_0) \\\\\n\\hline\n\\text{exists } \\delta   \u0026 \\text{exists a neighborhood  }  U \\text{of } x_0\\\\\n\\hline \n|x-x_0|\\le \\delta \\Rightarrow |f(x)-f(x_0)|\\le \\varepsilon    \u0026 f(U)\\subseteq V \\\\\n\\hline\n \\end{array}$$\n","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Exact-Inference":{"title":"Exact Inference","content":"Given samples from a probabilistic model of a system, a frequent research question is to infer certain other properties about the system, or otherwise reduce the uncertainty in the sampled information - as in sensor fusion problems. In certain scenarios, if we make the right assumptions, we can compute exact, deterministic solutions. A classical example of such an algorithm is the Kalman filter, which generalizes to [[notes/Gaussian Belief Propagation (GBP)]].","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Exponential-Families":{"title":"Exponential Families","content":"An exponential family of probability distributions is associated with a set of functions $\\phi=\\lbrace\\phi_\\alpha:\\mathcal{X}^m\\rightarrow\\mathbb{R}|\\alpha\\in\\mathcal{I}\\rbrace$ called the sufficient statistics, for index set $\\mathcal{I}$. The canonical parameters $\\theta=\\lbrace\\theta_\\alpha\\in\\mathbb{R}|\\alpha\\in\\mathcal{I}\\rbrace$ are used to specify the particular distribution within the familty, with probability density\n$$p_\\theta(x) = \\exp\\lbrace\\theta\\cdot\\phi(x) - A(\\theta)\\rbrace$$\nwhere the quantity $A(\\theta)$ is the log partition function - provides normalization. Some examples of [[notes/Graphical Models]] can easily be shown to represent exponential families, such as the [[notes/Ising Model]], [[notes/Gaussian MRF]] or [[notes/Gaussian Mixture Model]].","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Gaussian-Belief-Propagation-GBP":{"title":"Gaussian Belief Propagation (GBP)","content":"With an understanding of Gaussian algebra, [[notes/Graphical Models|PGMs]], tree decomposition, and variable elimination, it becomes apparent that GBP is nothing more than a clever application of the distributive law. Certain SLAM algorithms can be represented by a factor graph and with a smart choice of elimination ordering, [[notes/Exact Inference]] can be performed using GBP.\n\n![[visuals/factor_graph_slam.png]]","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Gaussian-MRF":{"title":"Gaussian MRF","content":"A Gaussian MRF is a [[notes/Graphical Models|markov random field]] whose edges represent the elements of a precision matrix.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Gaussian-Mixture-Model":{"title":"Gaussian Mixture Model","content":"\u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD\nConsider a  multinomial random variable $X$ with values in $\\lbrace 0,1,\\dots,r-1\\rbrace$ that specifies the choice of distribution from a collection of $r$ Gaussians parametrized by $\\lbrace\\mu_j,\\sigma^2_j\\rbrace$ for $X=j$. The distribution of $X$ is an [[notes/Exponential Families|exponential family]] with sufficient statistics $\\lbrace \\mathbb{I}_j[x]\\rbrace$ and canonical parameters $\\alpha$. Each Gaussian $Y$ conditioned on $X$ is also an exponential family with sufficient statistics $\\lbrace y,y^2\\rbrace$ and canonical parameters $(\\gamma_j,\\gamma'_j) := (\\frac{\\mu_j}{\\sigma^2_j},-\\frac{1}{2\\sigma^2_j})$. The resulting PDF is of the form\n$$p_{\\theta} = p_\\alpha(x)p_\\gamma(y|x) \\propto \\exp\\left\\lbrace \\sum_j\\alpha_j\\mathbb{I}_j[x] + \\sum_j (\\gamma_jy+\\gamma'_jy^2)\\mathbb{I}_j[x]\\right\\rbrace$$\nThe pair of random variables $(X,Y)$ can be used to create more complex [[notes/Graphical Models]] to describe multivariate distributions of the form $((X_1,Y_1),\\dots,(X_m,Y_m))$.\n=======\nConsider a  multinomial random variable $X$ with values in $\\lbrace 0,1,\\dots,r-1\\rbrace$ that specifies the choice of distribution from a collection of $r$ Gaussians parametrized by $\\lbrace\\mu_j,\\sigma^2_j\\rbrace$ for $X=j$. The distribution of $X$ is an [[notes/Exponential Families|exponential family]] with sufficient statistics $\\lbrace\\mathbb{I}_j[x]\\rbrace$ and canonical parameters $\\alpha$. Each Gaussian $Y$ conditioned on $X$ is also an exponential family with sufficient statistics $\\lbrace y,y^2\\rbrace$ and canonical parameters $(\\gamma_j,\\gamma'_j) := (\\frac{\\mu_j}{\\sigma^2_j},-\\frac{1}{2\\sigma^2_j})$. The resulting PDF is of the form\n$$p_\\theta = p_\\alpha(x)p_\\gamma(y|x) \\propto \\exp\\left\\lbrace\\sum_j\\alpha_j\\mathbb{I}_j[x] + \\sum_j (\\gamma_jy+\\gamma'_jy^2)\\mathbb{I}_j[x]\\right\\rbrace$$\nThe pair of random variables $(X,Y)$ can be used to create more complex [[notes/Graphical Models]] to describe multivariate distributions of the form $((X_1,Y_1),\\dots,(X_m,Y_m))$.\n\u003e\u003e\u003e\u003e\u003e\u003e\u003e 9681f97 (trying to fix bracing v4)\n","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Graphical-Models":{"title":"Graphical Models","content":"There are a variety of graphical models, which explicitly represent the structure of a joint PDF.  Three popular variants are described below. The more general framework of describing interaction between nodes - think particles - using graphs is extremely versatile.\n\n## Bayesian Networks\nA Bayesian network $\\mathcal{B}=(V,E)$ is a directed acyclic graph (DAG). Its nodes $V = \\lbrace X_1\\dots X_n\\rbrace$ represent random variables and the edges $E \\subset V\\times V$ show conditional dependencies. It encodes a probability distribution where factors are either a prior of a variable, or a posterior conditioned on its parents. If we denote the parent nodes of $X_i$ as $\\pi_i$, the joint PDF over $n$ variables is defined as\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) = \\prod_i p(x_i|\\pi_i)p(x_i)$$\n\n## Markov Random Fields\nA Markov random field (MRF) is an undirected graph $\\mathcal{M}=(V,E)$, which encodes conditional independence between variables in a joint PDF. For example, in a three node graph $X-Z-Y$, the joint probability is $p_{XYZ}(x,y,z) = p_{X|Z}(x;z)p_{Y|Z}(y;z)p_Z(z)$. In particular, since all paths between nodes $X$ and $Y$ on the graph pass through node $Z$, we deduce that $X$ and Y are independent conditioned on $Z$. This is similar to the Markov property and motivates a factorization over cliques $\\lbrace (X,Z),(Y,Z)\\rbrace$. A clique is a complete induced subgraph and is maximal when it is not contained within a larger clique. If nodes in $V$ are grouped into a set of maximal cliques $C$, the joint probability represented by the undirected graph can be written as a product of potential functions with inputs in $C$ and normalizing partition function $Z$.\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) =\\frac{1}{Z}\\prod_{c\\,\\in C} \\psi_{c}(x_{c}) $$\nA DAG can be converted to an undirected graph through moralization -- fully connecting each node's parents. This can result in loss of some conditional independencies though.\n\n## Factor Graphs\nFactor graph $\\mathcal{F}=(V,E,F)$ is an undirected bipartite graph with edges $E\\subseteq V\\times F$ between nodes $V$ representing random variables and nodes $F$ for factors, making the factorization explicit. A variable connected to a factor means it is given as input to the factor function. Hence, the joint PDF with normalizing partition function $Z$ can be expressed as:\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) =\\frac{1}{Z}\\prod_{\\phi\\,\\in F} \\phi(x_{\\phi})$$","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Homeomorphism":{"title":"Homeomorphism","content":"Given [[notes/Topological Space|topological spaces]] $\\mathcal{X}$ and $\\mathcal{Y}$, a function $g:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is a *homeomorphism* if it:\n- is a bijection\n- is [[notes/Continuous Function|continuous]]\n- has a continuous inverse.\n\nA homeomorphism is explicitly bicontinuous, since there exist bijective functions that are continuous in one direction but discontinuous in the other. For example, the map $\\rho = \\theta\\mapsto e^{i\\theta}:[0,2\\pi)\\to S^1\\subset\\mathbb{C}$ where $S^1$ is the unit circle on the complex plane. The inverse map $\\rho^{-1}$ is not continuous, since $[0,r)$ is an open set of $[0,2\\pi)$ for any $r\\in(0,2\\pi)$, but $\\rho([0,r))$ is not an open set of $S^1$ due to the interval being closed on one side.  ([idea source](https://math.stackexchange.com/a/1855569))\n\nIf $\\mathcal{X}$ is homeomorphic to a subspace in $\\mathcal{Y}$, it is called *embedded*.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Ising-Model":{"title":"Ising Model","content":"In statistical physics, the Ising Model is classically used to model the directions of \"spin\" in a magnet. It is an example of a [[notes/Graphical Models|graphical model]] associated with an [[notes/Exponential Families|exponential family]]. In particular, consider the PDF\n$$p_\\theta(x) = \\exp\\left\\lbrace\\sum_{s\\in V}\\theta_sx_s + \\sum_{(s,t)\\in E} \\theta_{st}x_sx_t - A(\\theta) \\right\\rbrace$$\nwhere $x\\in\\lbrace 0,1\\rbrace^m$ represents the spin (up or down) of $m$ dipoles in an abstraction of the material. The sufficient statistics enables variation of the magnetic field strength per spin dipole, as well as pair-wise spin interactions. A generalized Ising Model allows for $k$-cliques rather than only interaction between pairs of nodes. In the extreme, where all monomials up to $k=m$ are considered, any distribution over a binary random vector can be represented.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Manifold":{"title":"Manifold","content":"A manifold is a topological space that locally resembles Euclidean space near each point.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Topological-Space":{"title":"Topological Space","content":"A topological space $\\mathcal{X}$, also denoted $(\\mathcal{S},\\mathcal{T})$, is a collection containing the empty set, $\\mathcal{S}$, and an associated topology $\\mathcal{T}$ - a set of neighborhoods (subsets) of $\\mathcal{S}$. Formally, the elements of  $\\mathcal{T}$ are *open sets*, since the open set for a point $p\\in \\mathcal{S}$ will contain all other points sufficiently near $p$. A set is considered *closed* if its complement is open.\n","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/Variational-Inference":{"title":"Variational Inference","content":"When a problem is called *variational*, think approximate. When [[notes/Exact Inference]] is intractable, we consider a variational approach.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/notes/blogTestMarcus":{"title":"blogTestMarcus","content":"Test 1 $\\lbrace\\mu_j,\\sigma^2_j\\rbrace$\n\nTest 2 $\\lbrace \\mu_j, \\sigma^2_i \\rbrace$ \n\nTest 3 $\\lbrace \\mu_{j}, \\sigma^2_{i} \\rbrace$ \n\nTest 4 $\\{x\\}$\n\nTest 5 $\\mu_j \\mu_j {\\mu_j} \\mu_{j}$\n","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null},"/posts/The-Metamorphosis-of-Prime-Intellect-book-review":{"title":"The Metamorphosis of Prime Intellect (book review)","content":"## Review\nIn this novella by Roger Williams, an AGI named Prime Intellect masters physics through the so-called \"Correlation Effect\", thereby becoming god. Scary right? Fortunately, Prime Intellect keeps humanity alive due to the three laws of robotics as defined by Isaac Asimov. The book is equal parts 90s futurism and total perversion - the writing is definitely R-rated. The explicit descriptions of torture and sex might put off interested readers. However, I also respect Williams for not holding back. \n\nThe book is inevitably flawed. Any author writing prose that causes readers to contemplate humanity, intelligence, and meaning itself, has to cleverly hide their inability to provide an answer. Williams is not the strongest writer, but his passion for the fiction is unmistakeable. If you're intrigued by the idea of a technological singularity birthing a benevolent god, and aren't put off by crude writing, give it a read. Below I recall some juicy quotes.\n## Quotes\nBody and mind:\n- Irreversible damage progressed beyond the actual neural network and affected the data structures which make you conscious and capable of memory.\n- A few others found that certain nerve poisons worked permanently, because they quickly destroyed the information content of the brain -- what Prime Intellect was beginning to consider the real human, rather than the tangible body.\n- Not realizing that memory is one of the more trivial functions of sentience.\n\nThroughout the text I was bothered by how strongly Williams enforced the idea that our minds are in the brain and separate from the primitive body. Also the assumption that memory and processing are separate, like in the Von Neumann architecture, was a tad out-dated.\n\nMachine learning:\n- Within each tiny processor in the massive Intellect were special functions of his own design, functions that could be reduced to hardware and done very efficiently with this new technology.\n- Among Prime Intellect's four thousand six hundred and twelve interlocking programs was one Lawrence called the `RANDOM_IMAGINATION_ENGINE`. Its sole purpose was to prowl for new associations that might fit somewhere in an empty area of the GAT (Global Association Table).\n\nSome of Williams's views on how a future AGI might function were insightful. The idea of having massively parallel yet simple computations (e.g. on GPUs) was definitely forward-looking, while the GAT, essentially a form of covariance matrix, implies the statistical nature of intelligence. However, he does not mention compression, which I believe is fundamental to intelligence, if not the defining feature. It is also explained that Prime Intellect's software has hand-crafted modules for different purposes, with more emphasis on inductive bias from a human inventor versus training from data. Very 90s indeed.\n\nPhysics:\n- ChipTec had found a loophole in the laws of quantum mechanics that allowed them to send a signal, not through space, but around space. From point A to point B without crossing the distance between the two points. Faster than light. Faster than anything.\n- Long-standing scientific questions were now trivially easy to answer. Scientists who had once spent billions of dollars setting up intricate experiments now spent their time thinking of the right questions to ask Prime Intellect.\n\nQuantum mechanics is briefly mentioned and treated like magic. Nevertheless, once it is revealed that Prime Intellect has become an artificial scientist, I no longer felt the need to concern myself with whether the author's depictions of physics were silly or not. I do believe that most scientists will gradually become prompt engineers.\n\nPleasant writing:\n- They cared only about the passion, were driven by it and it alone, and if it drove them to ruin it would not matter.\n- She was trying to work up the proper tone of righteous rage and it just wouldn't come. It would start, and then she would look at Lawrence and see a pathetic, tired man who already knew how badly he had fucked up and was doing what he could, which was next to nothing, to put things right.\n- Lawrence's clever pet was about to become a god.\n\nThere were some more shocking quotes that I liked, but omit here.","lastmodified":"2022-09-20T19:53:23.891611482Z","tags":null}}