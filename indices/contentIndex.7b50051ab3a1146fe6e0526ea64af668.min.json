{"/":{"title":"Home","content":"\nHowdy. I'm Nikola. This is my personal website, and it grows alongside my collection of interlinked notes.","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Exact-Inference":{"title":"Exact Inference","content":"Given samples from a probabilistic model of a system, a frequent research question is to infer certain other properties about the system, or otherwise reduce the uncertainty in the sampled information - as in sensor fusion problems. In certain scenarios, if we make the right assumptions, we can compute exact, deterministic solutions. A classical example of such an algorithm is the Kalman filter, which generalizes to [[notes/Gaussian Belief Propagation (GBP)]].","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Gaussian-Belief-Propagation-GBP":{"title":"Gaussian Belief Propagation (GBP)","content":"With an understanding of Gaussian algebra, [[notes/Graphical Models|PGMs]], tree decomposition, and variable elimination, it becomes apparent that GBP is nothing more than a clever application of the distributive law.\n\nAn interesting application is in SLAM algorithms with probabilistic model represented by a factor graph.\n\n![[visuals/factor_graph_slam.png]]","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Graphical-Models":{"title":"Graphical Models","content":"There are a variety of graphical models, which explicitly represent the structure of a joint PDF.  Three popular variants are described below. The more general framework of describing interaction between nodes - think particles - using graphs is extremely versatile.\n\n### Bayesian Networks\nA Bayesian network $\\mathcal{B}=(V,E)$ is a directed acyclic graph (DAG). Its nodes $V = \\{X_1\\dots X_n\\}$ represent random variables and the edges $E \\subset V\\times V$ show conditional dependencies. It encodes a probability distribution where factors are either a prior of a variable, or a posterior conditioned on its parents. If we denote the parent nodes of $X_i$ as $\\pi_i$, the joint PDF over $n$ variables is defined as\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) = \\prod_i p(x_i|\\pi_i)p(x_i)$$\n\n### Markov Random Fields\nA Markov random field (MRF) is an undirected graph $\\mathcal{M}=(V,E)$, which encodes conditional independence between variables in a joint PDF. For example, in a three node graph $X-Z-Y$, the joint probability is $p_{XYZ}(x,y,z) = p_{X|Z}(x;z)p_{Y|Z}(y;z)p_Z(z)$. In particular, since all paths between nodes $X$ and $Y$ on the graph pass through node $Z$, we deduce that $X$ and Y are independent conditioned on $Z$. This is similar to the Markov property and motivates a factorization over cliques $\\{(X,Z),(Y,Z)\\}$. A clique is a complete induced subgraph and is maximal when it is not contained within a larger clique. If nodes in $V$ are grouped into a set of maximal cliques $C$, the joint probability represented by the undirected graph can be written as a product of potential functions with inputs in $C$ and normalizing partition function $Z$.\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) =\\frac{1}{Z}\\prod_{c\\,\\in C} \\psi_{c}(x_{c}) $$\nA DAG can be converted to an undirected graph through moralization -- fully connecting each node's parents. This can result in loss of some conditional independencies though.\n\n### Factor Graphs\nFactor graph $\\mathcal{F}=(V,E,F)$ is an undirected bipartite graph with edges $E\\subseteq V\\times F$ between nodes $V$ representing random variables and nodes $F$ for factors, making the factorization explicit. A variable connected to a factor means it is given as input to the factor function. Hence, the joint PDF with normalizing partition function $Z$ can be expressed as:\n$$p_{X_1\\dots X_n}(x_1\\dots x_n) =\\frac{1}{Z}\\prod_{\\phi\\,\\in F} \\phi(x_{\\phi})$$","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Manifold":{"title":"Manifold","content":"A manifold is a topological space that locally resembles Euclidean space near each point.","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Topological-Space":{"title":"Topological Space","content":"A topological space $\\mathcal{X}$, also denoted $(\\mathcal{S},\\mathcal{T})$, is a collection containing the empty set, $\\mathcal{S}$, and an associated topology $\\mathcal{T}$ - a set of neighborhoods (subsets) of $\\mathcal{S}$. Formally, the elements of  $\\mathcal{T}$ are *open sets*, since the open set for a point $p\\in \\mathcal{S}$ will contain all other points sufficiently near $p$. Note, a set is considered *closed* if its complement is open.\n\nGiven topological spaces $\\mathcal{X}$ and $\\mathcal{Y}$, a function $f:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is *continuous* if the inverse image $f^{-1}(V)=U$ of an open set $V$ of $\\mathcal{Y}$ is an open set $U$ of $\\mathcal{X}$. Note how this generalizes the notion of a continuous function from real analysis - $f:\\mathbb{R}\\rightarrow \\mathbb{R}$ is continuous at $a$ if $f(a)=\\lim_{x\\rightarrow a}f(x)$. In other words, a function is continuous when points near $a$ give output near $f(a)$. [Table source](https://math.stackexchange.com/a/962688)\n$$\\begin{array}{|c|c|}\n\\hline\n\\text{Continuity on } \\Bbb R \u0026 \\text{Topological space} \\\\ \\hline\n\\text{Fix } \\varepsilon  \u0026 \\text{Fix a neighborhood }  V \\text{of } f(x_0) \\\\\n\\hline\n\\text{exists } \\delta   \u0026 \\text{exists a neighborhood  }  U \\text{of } x_0\\\\\n\\hline \n|x-x_0|\\le \\delta \\Rightarrow |f(x)-f(x_0)|\\le \\varepsilon    \u0026 f(U)\\subseteq V \\\\\n\\hline\n \\end{array}$$\nA function $g:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is a *homeomorphism* if it:\n- is a bijection\n- is continuous\n- has a continuous inverse.\nNote a homeomorphism is explicitly bicontinuous, since there exist bijective functions that are continuous in one direction but discontinuous in the other. For example, the map $\\rho = \\theta\\mapsto e^{i\\theta}:[0,2\\pi)\\to S^1\\subset\\mathbb{C}$ where $S^1$ is the unit circle on the complex plane. The inverse map $\\rho^{-1}$ is not continuous, as  ([idea source](https://math.stackexchange.com/a/1855569))\n\nIf $\\mathcal{X}$ is homeomorphic to a subspace in $\\mathcal{Y}$, it is called *embedded*. \n","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null},"/notes/Variational-Inference":{"title":"Variational Inference","content":"When a problem is called *variational*, think approximate. When [[notes/Exact Inference]] is intractable, we consider a variational approach.","lastmodified":"2022-09-11T21:42:37.466740655Z","tags":null}}